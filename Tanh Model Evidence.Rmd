---
title: "Tanh Model Evidence"
author: "Callum Macaulay"
date: "2024-11-25"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(laGP)
library(MASS)
library(ggplot2)
library(mvtnorm)
library(plgp)
library(deepgp)
library("glue")
library(lhs)
library(rmarkdown)



eps <- sqrt(.Machine$double.eps) 

```

```{r}
set.seed(4643581)

```

```{r}
#Data Generation

#Create Training data
train.locations <- matrix(seq(-10, 10, length.out = 20), ncol=1)

y.noisy <- as.vector(tanh(train.locations))
for (i in seq_along(y.noisy)) {
  y.noisy[i] <- y.noisy[i] + rnorm(1,mean=0, sd=0.3)
}


#create test data locations
test.locations <- matrix(seq(-10, 10, length.out = 200), ncol=1)
true.test.y <- tanh(test.locations)


#Plot of training data and target function
plot(train.locations, y.noisy, type = "p", col="black", main = "Plot of training data and target function", ylab="tanh(x)", xlab="x")
lines(test.locations, true.test.y, col="blue")


```


```{r}
#Generate empirical Bayes regularization priors

g <- garg(list(mle=TRUE, max=3), y.noisy)
d <- darg(list(mle=TRUE, max=150), train.locations)

#new GP
gpi<-newGP(train.locations, y.noisy, d=d$start, g=g$start, dK=TRUE)
mle <- jmleGP(gpi, c(d$min, d$max), c(g$min, g$max), d$ab, g$ab) 

#Optimized GP
gpi<-newGP(train.locations, y.noisy,d=mle$d, g=mle$g, dK=TRUE)

p.gpi<-predGP(gpi, test.locations, nonug = TRUE)


# Calculate relative likelihood
relative.like <- dnorm(true.test.y, mean = p.gpi$mean, sd =sqrt(diag(p.gpi$Sigma)))



#Realisation from GP and 90% interval
realisation <- rmvnorm(5, p.gpi$mean, p.gpi$Sigma)
q05 <- p.gpi$mean + qnorm(0.05, 0, sqrt(diag(p.gpi$Sigma)))
q95 <- p.gpi$mean + qnorm(0.95, 0, sqrt(diag(p.gpi$Sigma)))


#Plot Realisations
matplot(test.locations, t(realisation), type="l", col="grey", main="GP with MLE lengthscale")
lines(test.locations, q05, lwd=2, lty=2, col=2)
lines(test.locations, q95, lwd=2, lty=2, col=2)
lines(test.locations, p.gpi$mean, lwd=2)
lines(test.locations, tanh(test.locations), col="blue")
points(train.locations, y.noisy, pch=20, cex=2, )
legend(x=0, y=0.3,legend=("dots - Observed data \nred - 95% CI\nblue - target tanh function \ngrey - realisation from GP \nBlack - GP mean"), bty ="n")

plot(test.locations,relative.like, main="Relative Predictive Likelihood")



print(glue("The mean Relative Predictive Likelihood is {mean(relative.like)}"))
print(glue("The mean marginal log-likelihood is {mean(p.gpi$llik)}"))


deleteGP(gpi)
```

```{r}
# 2layer dgp with sq exp kernal
dgp<- fit_two_layer(train.locations, y.noisy, vecchia = FALSE, m = 10, nmcmc = 50000, cov = c("exp2"))
```

```{r}
#Diagnotic plots for mixing

plot(dgp$ll)
plot(dgp$g)
plot(dgp$theta_y)
plot(dgp$theta_w)

mean(dgp$ll[-1])
```


```{r}
#Predictions
p.dgp<-predict(dgp, x_new = test.locations, lite = FALSE, interval="predict", mean_map = TRUE)
```


```{r}
q05<- p.dgp$mean + qnorm(0.05, 0,  sqrt(diag(p.dgp$Sigma)))
q95 <- p.dgp$mean + qnorm(0.95, 0, sqrt(diag(p.dgp$Sigma)))


plot(test.locations, p.dgp$mean , type = "l", main="2 layer", ylim = c(-2, 2))
    points(train.locations, y.noisy, pch=20, cex=2)
  lines(test.locations, p.dgp$mean, lwd=2)
    lines(test.locations, q05, lwd=2, lty=2, col=2) 
    lines(test.locations, q95, lwd=2, lty=2, col=2) 
    lines(test.locations, tanh(test.locations), col="blue")
    legend(x=0, y=1,legend=("dots - Observed data \nred - 95% CI\nblue - target tanh function \nBlack - GP mean"), bty ="n")


relative.like<- dnorm(true.test.y, p.dgp$mean, sqrt(diag(p.dgp$Sigma)))


plot(test.locations,relative.like, main="Relative Predictive Likelihood")


print(glue("The mean Relative Predictive Likelihood is {mean(relative.like)}"))
print(glue("The mean marginal log-likelihood is {mean(dgp$ll[-1])}"))
```

```{r}
# Subtract noise variance (nugget) from the covariance matrix
Sigma_smooth <- p.dgp$Sigma - diag(mean(p.dgp$g), nrow(p.dgp$Sigma))

### Ensure the covariance matrix remains positive definite
Sigma_smooth <- (Sigma_smooth + t(Sigma_smooth)) / 2  # Enforce symmetry
eig <- eigen(Sigma_smooth)
Sigma_smooth <- eig$vectors %*% diag(pmax(eig$values, 1e-10)) %*% t(eig$vectors)

# Generate realizations without noise
realisation_smooth <- mvrnorm(5, p.dgp$mean, Sigma_smooth)

# Plot the smooth realizations
q05 <- p.dgp$mean + qnorm(0.05, 0, sqrt(diag(Sigma_smooth)))
q95 <- p.dgp$mean + qnorm(0.95, 0, sqrt(diag(Sigma_smooth)))

matplot(test.locations, t(realisation_smooth), col = rainbow(5), type = "l", main = "2 Layer (Smooth Realizations)", ylim = c(-2, 2))
points(train.locations, y.noisy, bg="black", pch = 21)
lines(test.locations, p.dgp$mean, lwd = 2, col = "black")
lines(test.locations, q05, lwd = 3, lty = 2, col = 2)  # 95% CI lower
lines(test.locations, q95, lwd = 3, lty = 2, col = 2)  # 95% CI upper
lines(test.locations, tanh(test.locations), col = "blue", lwd = 2)  # Target function
legend(x = 0, y = 0,  legend = c("dots - Observed data", "red - 95% CI", "blue - target tanh function",  "rainbow - smooth realization from GP", "black - GP mean"),bty = "n")


relative.like<- dnorm(true.test.y, p.t.dgp$mean, sqrt(diag(Sigma_smooth)))
print(glue("The mean Relative Predictive Likelihood is {mean(relative.like)}"))

```

```{r}
t.dgp<- fit_three_layer(train.locations, y.noisy, vecchia = FALSE, m = 10, nmcmc = 100000, cov = c("exp2"))


```

```{r}
plot(t.dgp$ll)
plot(t.dgp$g)
plot(t.dgp$theta_y)
plot(t.dgp$theta_w)

mean(t.dgp$ll[-1])
```


```{r}
p.t.dgp<-predict(t.dgp, x_new = test.locations, lite = FALSE, interval="predict", mean_map = TRUE)
```

```{r}
q05<- p.t.dgp$mean + qnorm(0.05, 0,  sqrt(diag(p.t.dgp$Sigma)))
q95 <- p.t.dgp$mean + qnorm(0.95, 0, sqrt(diag(p.t.dgp$Sigma)))


plot(test.locations, p.t.dgp$mean , type = "l", main="3 layer", ylim = c(-2, 2))
    points(train.locations, y.noisy, pch=20, cex=2)
  lines(test.locations, p.t.dgp$mean, lwd=2)
    lines(test.locations, q05, lwd=2, lty=2, col=2) 
    lines(test.locations, q95, lwd=2, lty=2, col=2) 
    lines(test.locations, tanh(test.locations), col="blue")
    legend(x=0, y=0,legend=("dots - Observed data \nred - 95% CI\nblue - target tanh function\nBlack - GP mean"), bty ="n")


relative.like<- dnorm(true.test.y, p.t.dgp$mean, sqrt(diag(p.t.dgp$Sigma)))

plot(test.locations,relative.like, main="Relative Predictive Likelihood")


print(glue("The mean Relative Predictive Likelihood is {mean(relative.like)}"))
print(glue("The mean marginal log-likelihood is {mean(t.dgp$ll[-1])}"))
```


```{r}
# Subtract noise variance (nugget) from the covariance matrix
Sigma_smooth <- p.t.dgp$Sigma - diag(mean(p.t.dgp$g), nrow(p.t.dgp$Sigma))

### Ensure the covariance matrix remains positive definite
Sigma_smooth <- (Sigma_smooth + t(Sigma_smooth)) / 2  # Enforce symmetry
eig <- eigen(Sigma_smooth)
Sigma_smooth <- eig$vectors %*% diag(pmax(eig$values, 1e-10)) %*% t(eig$vectors)

# Generate realizations without noise
realisation_smooth <- mvrnorm(5, p.t.dgp$mean, Sigma_smooth)

# Plot the smooth realizations
q05 <- p.t.dgp$mean + qnorm(0.05, 0, sqrt(diag(Sigma_smooth)))
q95 <- p.t.dgp$mean + qnorm(0.95, 0, sqrt(diag(Sigma_smooth)))

matplot(test.locations, t(realisation_smooth), col = rainbow(5), type = "l", main = "3 Layer (Smooth Realizations)", ylim = c(-2, 2))
points(train.locations, y.noisy, bg="black", pch = 21)
lines(test.locations, p.t.dgp$mean, lwd = 2, col = "black")
lines(test.locations, q05, lwd = 3, lty = 2, col = 2)  # 95% CI lower
lines(test.locations, q95, lwd = 3, lty = 2, col = 2)  # 95% CI upper
lines(test.locations, tanh(test.locations), col = "blue", lwd = 2)  # Target function
legend(x = 0, y = 0,  legend = c("dots - Observed data", "red - 95% CI", "blue - target tanh function",  "rainbow - smooth realization from GP", "black - GP mean"),bty = "n")


relative.like<- dnorm(true.test.y, p.t.dgp$mean, sqrt(diag(Sigma_smooth)))
print(glue("The mean Relative Predictive Likelihood is {mean(relative.like)}"))

```

